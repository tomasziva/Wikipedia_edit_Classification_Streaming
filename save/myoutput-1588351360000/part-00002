{"title_page": "One-class classification", "text_new": "In [[machine learning]], '''one-class classification''' ('''OCC'''), also known as '''unary classification''' or '''class-modelling''', tries to ''identify'' objects of a specific class amongst all objects, by primarily learning from a [[training set]] containing only the objects of that class,<ref>{{cite journal | vauthors = Oliveri P | title = Class-modelling in food analytical chemistry: Development, sampling, optimisation and validation issues - A tutorial | journal = Analytica Chimica Acta | volume = 982 | pages = 9\u201319 | date = August 2017 | pmid = 28734370 | doi = 10.1016/j.aca.2017.05.013 }}</ref> although there exist variants of one-class classifiers where counter-examples are used to further refine the classification boundary. This is different from and more difficult than the traditional [[classification (machine learning)|classification]] problem, which tries to ''distinguish between'' two or more classes with the training set containing objects from all the classes. Examples include the monitoring of helicopter gearboxes,<ref>{{cite article | url= http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.40.3663&rep=rep1&type=pdf | vauthors = Japkowicz, N., Myers, C., and Gluck, M. | date = 1995 | title = A Novelty Detection Approach to Classification | publisher = IJCAI-95}}</ref><ref>{{cite thesis | url= https://rucore.libraries.rutgers.edu/rutgers-lib/59019/ | vauthors = Japkowicz, N. | date = 1999 | title = Concept-Learning in the Absence of Counter-Examples:An Autoassociation-Based Approach to Classification | publisher = Rutgers University}}</ref><ref>{{cite article | url= https://link.springer.com/content/pdf/10.1023/A:1007660820062.pdf | vauthors = Japkowicz, N. | date = 2001 | title = Supervised Versus Unsupervised Binary-Learning by Feedforward Neural Networks | publisher = Machine Learning Journal}}</ref> motor failure prediction,<ref>{{cite article | url= http://papers.nips.cc/paper/1077-a-neural-network-autoassociator-for-induction-motor-failure-prediction.pdf | vauthors = Petsche, T., Marcantonio, A., Darken, C., Hanson, S., Kuhn, G. and Santoso, I. | date = 1996 | title = A Neural Network Autoassociator for\nInduction Motor Failure Prediction | publisher = NIPS}}</ref> or the operational status of a nuclear plant as 'normal':<ref name=\":1\">{{cite thesis | url = http://homepage.tudelft.nl/n9d04/thesis.pdf | vauthors = Tax D | date = 2001 | title =  One-class classification: Concept-learning in the absence of counter-examples. | degree = Ph.D. | publisher = University of Delft | location = The Netherlands }}</ref> In this scenario, there are few, if any, examples of catastrophic system states; only the statistics of normal operation are known.\n\nWhile many of the above approaches focus on the case of removing a small number of outliers or anomalies, one can also learn the other extreme, where the single class covers a small coherent subset of the data, using an [[Information bottleneck method|information bottleneck]] approach.<ref>{{cite journal|last=Crammer|first=Koby|date=2004|title=A needle in a haystack: local one-class optimization|url=https://dl.acm.org/citation.cfm?id=1015399|journal=ICML Proceedings of the Twenty-first International Conference on Machine Learning|volume=|pages=26|via=}}</ref>\n\n==Overview==\nThe term one-class classification (OCC) was coined by Moya & Hush (1996)<ref>{{cite journal | last1 = Moya | first1 = M. | last2 = Hush | first2 = D. | year = 1996 | title = Network constraints and multi- objective optimization for one-class classification | url = | journal = Neural Networks | volume = 9 | issue = 3| pages = 463\u2013474 | doi = 10.1016/0893-6080(95)00120-4 }}</ref> and many applications can be found in scientific literature, for example [[outlier detection]], [[anomaly detection]], [[novelty detection]]. A feature of OCC is that it uses only sample points from the assigned class, so that a representative sampling is not strictly required for non-target classes.<ref>{{cite journal| vauthors = Rodionova OY, Oliveri P, Pomerantsev AL |date=2016-12-15|title=Rigorous and compliant approaches to one-class classification |journal=Chemometrics and Intelligent Laboratory Systems|volume=159|pages=89\u201396|doi=10.1016/j.chemolab.2016.10.002}}</ref>\n\n== Introduction ==\n[[File:One-class_data_description_TAX.png|thumb|right|The hypersphere containing the target data having center a and radius R. Objects on the boundary are support vectors, and two objects lie outside the boundary having slack greater than 0.]]\nSVM based one-class classification (OCC) relies on identifying the smallest hypersphere (with radius r, and center c) consisting of all the data points.<ref>{{cite journal |last1=Zineb |first1=Noumir |last2=Honeine |first2=Paul |last3=Richard |first3=Cedue |title=On simple one-class classification methods. |journal=IEEE International Symposium on Information Theory Proceedings |date=2012 |publisher=IEEE, 2012}}</ref> This method is called Support Vector Data Description (SVDD). Formally, the problem can be defined in the following constrained optimization form,\n\n<math display=\"block\"> \\min_{r,c} r^2 \\text{ subject to, } ||\\Phi(x_i) - c||^2 \\le r^2 \\;\\; \\forall i = 1, 2, ..., n</math>\n\nHowever, the above formulation is highly restrictive, and is sensitive to the presence of outliers. Therefore, a flexible formulation, that allow for the presence of outliers is formulated as shown below,\n\n<math>\\min_{r,c,\\zeta} r^2 + \\frac{1}{\\nu n}\\sum_{i=1}^{n}\\zeta_i</math>\n\n<math>\\text{subject to, } ||\\Phi(x_i) - c||^2 \\le r^2 + \\zeta_i \\;\\; \\forall i = 1, 2, ..., n</math>\n\nFrom Karush-Kuhn-Tucker (KKT) optimality conditions, we get\n\n<math>c = \\sum_{i=1}^{n}\\alpha_i\\Phi(x_i),</math>\n\nwhere the <math>\\alpha_i's</math>are the solution to the following optimization problem:\n\n<math>\\max_\\alpha \\sum_{i=1}^{n}\\alpha_i\\kappa(x_i, x_i) - \\sum_{i, j = 1}^{n}\\alpha_i\\alpha_j\\kappa(x_i, x_j)\n</math>\n\nsubject to, <math>\\sum_{i=1}^{n}\\alpha_i = 1 \\text{ and } 0 \\le \\alpha_i \\le \\frac{1}{\\nu n} \\text{for all } i = 1,2,...,n.</math>\n\nThe introduction of kernel function provide additional flexibility to the One-class [[Support-vector machine|SVM]] (OSVM) algorithm.<ref>{{Cite journal|last=Khan|first=Shehroz S.|last2=Madden|first2=Michael G.|date=2010|editor-last=Coyle|editor-first=Lorcan|editor2-last=Freyne|editor2-first=Jill|title=A Survey of Recent Trends in One Class Classification|journal=Artificial Intelligence and Cognitive Science|volume=6206|series=Lecture Notes in Computer Science|language=en|publisher=Springer Berlin Heidelberg|pages=188\u2013197|doi=10.1007/978-3-642-17080-5_21|isbn=9783642170805|hdl=10379/1472|hdl-access=free}}</ref>\n\n=== PU learning ===\nA similar problem is '''PU learning''', in which a [[binary classification|binary classifier]] is learned in a [[semi-supervised learning|semi-supervised]] way from only ''positive'' and ''unlabeled'' sample points.<ref>{{cite book|title=Web Data Mining|last=Liu|first=Bing|publisher=Springer|year=2007|pages=165\u2013178}}</ref>\n\nIn PU learning, two sets of examples are assumed to be available for training: the positive set <math>P</math> and a ''mixed set'' <math>U</math>, which is assumed to contain both positive and negative samples, but without these being labeled as such. This contrasts with other forms of semisupervised learning, where it is assumed that a labeled set containing examples of both classes is available in addition to unlabeled samples. A variety of techniques exist to adapt [[supervised learning|supervised]] classifiers to the PU learning setting, including variants of the [[Expectation-maximization|EM algorithm]]. PU learning has been successfully applied to [[text classification|text]],<ref>{{cite conference |author=Bing Liu |author2=Wee Sun Lee |author3=Philip S. Yu |author3-link=Philip S. Yu |author4=Xiao-Li Li |last-author-amp=yes |year=2002 |title=Partially supervised classification of text documents |conference=ICML |pages=8\u201312}}</ref><ref>{{cite conference |author=Hwanjo Yu |author2=Jiawei Han |author3=Kevin Chen-Chuan Chang |title=PEBL: positive example based learning for web page classification using SVM |conference=ACM SIGKDD |year=2002}}</ref><ref>{{cite conference |author=Xiao-Li Li |author2=Bing Liu |last-author-amp=yes |title=Learning to classify text using positive and unlabeled data |conference=IJCAI |year=2003}}</ref> time series,<ref>{{cite conference |author=Minh Nhut Nguyen |author2=Xiao-Li Li |author3=See-Kiong Ng |last-author-amp=yes |title=Positive Unlabeled Learning for Time Series Classification |conference=IJCAI |year=2011}}</ref> [[bioinformatics]] tasks,<ref>{{cite conference |author=Peng Yang |author2=Xiao-Li Li |author3=Jian-Ping Mei |author4=Chee-Keong Kwoh |author5=See-Kiong Ng |last-author-amp=yes |title=Positive-Unlabeled Learning for Disease Gene Identification |conference=Bioinformatics, Vol 28(20)|year=2012}}</ref> and Remote-Sensing Data.<ref>{{cite journal|last=Li|first=W.|last2=Guo|first2=Q.|last3=Elkan|first3=C.|date=February 2011|title=A Positive and Unlabeled Learning Algorithm for One-Class Classification of Remote-Sensing Data|journal=IEEE Transactions on Geoscience and Remote Sensing|volume=49|issue=2|pages=717\u2013725|doi=10.1109/TGRS.2010.2058578|issn=0196-2892}}</ref>\n\n== Approaches ==\nSeveral approaches have been proposed to solve one-class classification (OCC). The approaches can be distinguished into three main categories, '''density estimation''', '''boundary methods''', and '''reconstruction methods'''.<ref name=\":1\" />\n\n==== Density estimation methods ====\nDensity estimation methods rely on estimating the density of the data points, and set the threshold. These methods rely on assuming distributions, such as Gaussian, or a [[Poisson distribution]]. Following which discordancy tests can be used to test the new objects. These methods are robust to scale variance.\n\n'''Gaussian model'''<ref>{{Cite book|url=https://books.google.com/?id=T0S0BgAAQBAJ&pg=PP1&dq=neural+networks+for+pattern+recognition|title=Neural Networks for Pattern Recognition|last=Bishop|first=Christopher M.|last2=Bishop|first2=Professor of Neural Computing Christopher M.|date=1995-11-23|publisher=Clarendon Press|isbn=9780198538646|language=en}}</ref> is one the simplest method to create one-class classifiers. Due to Central Limit Theorem (CLT),<ref>{{Cite journal|last=R|first=Ullman Neil|date=2017-01-01|title=Elementary statistics|url=http://archives.umc.edu.dz/handle/123456789/116529}}</ref> these methods work best when large number of samples are present, and they are perturbed by small independent error values. The probability distribution for a d-dimensional object is given by:\n\n<math>p_{\\mathcal{N}}(x;\\mu;\\Sigma) = \\frac{1}{(2\\pi)^{\\frac{d}{2}} |\\Sigma|^\\frac{1}{2}}\\exp\\{-\\frac{1}{2}(z-\\mu)^T \\Sigma^{-1} (z - \\mu) \\}</math>\n\nWhere, '''<math>\\mu</math>'''is the mean and '''<math>\\Sigma </math>''' is the covariance matrix. Computing the inverse of covariance matrix ('''<math>\\Sigma^{-1}</math>''') is the costliest operation, and in the cases where the data is not scaled properly, or data has singular directions pseudo-inverse <math>\\Sigma^+</math>is used to approximate the inverse, and is calculated as <math>\\Sigma^T(\\Sigma \\Sigma^T)^{-1}</math>.<ref>{{Cite web|url=http://bookstore.siam.org/wc02/|title=Introduction to Applied Mathematics|website=SIAM Bookstore|language=en|access-date=2019-04-29}}</ref>\n\n==== Boundary methods ====\nBoundary methods focus on setting boundaries around a few set of points, called target points. These methods attempt to optimize the volume. Boundary methods rely on distances, and hence are not robust to scale variance. K-centers method, NN-d, and SVDD are some of the key examples.\n\n'''K-centers'''\n\nIn K-center algorithm,<ref>{{Cite journal|last=Ypma|first=Alexander|last2=Duin|first2=Robert P. W.|date=1998|editor-last=Niklasson|editor-first=Lars|editor2-last=Bod\u00e9n|editor2-first=Mikael|editor3-last=Ziemke|editor3-first=Tom|title=Support objects for domain approximation|journal=Icann 98|series=Perspectives in Neural Computing|language=en|publisher=Springer London|pages=719\u2013724|doi=10.1007/978-1-4471-1599-1_110|isbn=9781447115991}}</ref> <math>k</math> small balls with equal radius are placed to minimize the maximum distance of all minimum distances between training objects and the centers. Formally, the following error is minimized,\n\n<math>\\varepsilon_{k-center} = \\max_i ( \\min_k || x_i - \\mu_k ||^2 )</math>\n\nThe algorithm uses forward search method with random initialization, where the radius is determined by the maximum distance of the object, any given ball should capture. After the centers are determined, for any given test object '''<math>z</math>''' the distance can be calculated as,\n\n<math>d_{k-centr}(z) = \\min_k || z - \\mu_k ||^2</math>\n\n==== Reconstruction methods ====\nReconstruction methods use prior knowledge and generating process to build a generating model that best fits the data. New objects can be described in terms of a state of the generating model. Some examples of reconstruction methods for OCC are, k-means clustering, learning vector quantization, self-organizing maps, etc.\n\n== Applications ==\n\n=== Document classification ===\nThe basic Support Vector Machine (SVM) paradigm is trained using both positive and negative examples, however studies have shown there are many valid reasons for using ''only'' positive examples. When the SVM algorithm is modified to only use positive examples, the process is considered one-class classification. One situation where this type of classification might prove useful to the SVM paradigm is in trying to identify a web browser\u2019s sites of interest based only off of the user\u2019s browsing history.\n\n=== Biomedical studies ===\nOne-class classification can be particularly useful in biomedical studies where often data from other classes can be difficult or impossible to obtain. In studying biomedical data it can be difficult and/or expensive to obtain the set of labeled data from the second class that would be necessary to perform a two-class classification. A study from The Scientific World Journal found that the typicality approach is the most useful in analysing biomedical data because it can be applied to any type of dataset (continuous, discrete, or nominal).<ref name=\":0\">{{cite journal | vauthors = Irigoien I, Sierra B, Arenas C | title = Towards application of one-class classification methods to medical data | journal = TheScientificWorldJournal | volume = 2014 | pages = 730712 | date = 2014 | pmid = 24778600 | pmc = 3980920 | doi = 10.1155/2014/730712 }}</ref> The typicality approach is based on the clustering of data by examining data and placing it into new or existing clusters.<ref>{{cite journal | vauthors = Irigoien I, Arenas C | title = INCA: new statistic for estimating the number of clusters and identifying atypical units | journal = Statistics in Medicine | volume = 27 | issue = 15 | pages = 2948\u201373 | date = July 2008 | pmid = 18050154 | doi = 10.1002/sim.3143 }}</ref> To apply typicality to one-class classification for biomedical studies, each new observation, <math>y_0\n</math>, is compared to the target class, <math>C</math>, and identified as an outlier or a member of the target class.<ref name=\":0\" />\n\n== See also ==\n*[[Multiclass classification]]\n*[[Anomaly detection]]\n*[[Supervised learning]]\n\n== References ==\n{{reflist|30em}}\n\n[[Category:Statistical classification]]\n[[Category:Classification algorithms]]\n", "text_old": "In [[machine learning]], '''one-class classification''' ('''OCC'''), also known as '''unary classification''' or '''class-modelling''', tries to ''identify'' objects of a specific class amongst all objects, by primarily learning from a [[training set]] containing only the objects of that class,<ref>{{cite journal | vauthors = Oliveri P | title = Class-modelling in food analytical chemistry: Development, sampling, optimisation and validation issues - A tutorial | journal = Analytica Chimica Acta | volume = 982 | pages = 9\u201319 | date = August 2017 | pmid = 28734370 | doi = 10.1016/j.aca.2017.05.013 }}</ref> although there exist variants of one-class classifiers where counter-examples are used to further refine the classification boundary. This is different from and more difficult than the traditional [[classification (machine learning)|classification]] problem, which tries to ''distinguish between'' two or more classes with the training set containing objects from all the classes. Examples include the monitoring of helicopter gearboxes<ref>{{cite article | url= http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.40.3663&rep=rep1&type=pdf | vauthors = Japkowicz, N., Myers, C., and Gluck, M. | date = 1995 | title = A Novelty Detection Approach to Classification | publisher = IJCAI-95}}</ref><ref> {{cite thesis | url= https://rucore.libraries.rutgers.edu/rutgers-lib/59019/ | vauthors = Japkowicz, N. | date = 1999 | title = Concept-Learning in the Absence of Counter-Examples:An Autoassociation-Based Approach to Classification | publisher = Rutgers University}}</ref> <ref> {{cite article | url= https://link.springer.com/content/pdf/10.1023/A:1007660820062.pdf | vauthors = Japkowicz, N. | date = 2001 | title = Supervised Versus Unsupervised Binary-Learning by Feedforward Neural Networks | publisher = Machine Learning Journal}}</ref>, motor failure prediction <ref> {{cite article | url= http://papers.nips.cc/paper/1077-a-neural-network-autoassociator-for-induction-motor-failure-prediction.pdf | vauthors = Petsche, T., Marcantonio, A., Darken, C., Hanson, S., Kuhn, G. and Santoso, I. | date = 1996 | title = A Neural Network Autoassociator for\nInduction Motor Failure Prediction | publisher = NIPS}}</ref>, or the operational status of a nuclear plant as 'normal':<ref name=\":1\">{{cite thesis | url = http://homepage.tudelft.nl/n9d04/thesis.pdf | vauthors = Tax D | date = 2001 | title =  One-class classification: Concept-learning in the absence of counter-examples. | degree = Ph.D. | publisher = University of Delft | location = The Netherlands }}</ref> In this scenario, there are few, if any, examples of catastrophic system states; only the statistics of normal operation are known.\n\nWhile many of the above approaches focus on the case of removing a small number of outliers or anomalies, one can also learn the other extreme, where the single class covers a small coherent subset of the data, using an [[Information bottleneck method|information bottleneck]] approach.<ref>{{cite journal|last=Crammer|first=Koby|date=2004|title=A needle in a haystack: local one-class optimization|url=https://dl.acm.org/citation.cfm?id=1015399|journal=ICML Proceedings of the Twenty-first International Conference on Machine Learning|volume=|pages=26|via=}}</ref>\n\n==Overview==\nThe term one-class classification (OCC) was coined by Moya & Hush (1996)<ref>{{cite journal | last1 = Moya | first1 = M. | last2 = Hush | first2 = D. | year = 1996 | title = Network constraints and multi- objective optimization for one-class classification | url = | journal = Neural Networks | volume = 9 | issue = 3| pages = 463\u2013474 | doi = 10.1016/0893-6080(95)00120-4 }}</ref> and many applications can be found in scientific literature, for example [[outlier detection]], [[anomaly detection]], [[novelty detection]]. A feature of OCC is that it uses only sample points from the assigned class, so that a representative sampling is not strictly required for non-target classes.<ref>{{cite journal| vauthors = Rodionova OY, Oliveri P, Pomerantsev AL |date=2016-12-15|title=Rigorous and compliant approaches to one-class classification |journal=Chemometrics and Intelligent Laboratory Systems|volume=159|pages=89\u201396|doi=10.1016/j.chemolab.2016.10.002}}</ref>\n\n== Introduction ==\n[[File:One-class_data_description_TAX.png|thumb|right|The hypersphere containing the target data having center a and radius R. Objects on the boundary are support vectors, and two objects lie outside the boundary having slack greater than 0.]]\nSVM based one-class classification (OCC) relies on identifying the smallest hypersphere (with radius r, and center c) consisting of all the data points.<ref>{{cite journal |last1=Zineb |first1=Noumir |last2=Honeine |first2=Paul |last3=Richard |first3=Cedue |title=On simple one-class classification methods. |journal=IEEE International Symposium on Information Theory Proceedings |date=2012 |publisher=IEEE, 2012}}</ref> This method is called Support Vector Data Description (SVDD). Formally, the problem can be defined in the following constrained optimization form,\n\n<math display=\"block\"> \\min_{r,c} r^2 \\text{ subject to, } ||\\Phi(x_i) - c||^2 \\le r^2 \\;\\; \\forall i = 1, 2, ..., n</math>\n\nHowever, the above formulation is highly restrictive, and is sensitive to the presence of outliers. Therefore, a flexible formulation, that allow for the presence of outliers is formulated as shown below,\n\n<math>\\min_{r,c,\\zeta} r^2 + \\frac{1}{\\nu n}\\sum_{i=1}^{n}\\zeta_i</math>\n\n<math>\\text{subject to, } ||\\Phi(x_i) - c||^2 \\le r^2 + \\zeta_i \\;\\; \\forall i = 1, 2, ..., n</math>\n\nFrom Karush-Kuhn-Tucker (KKT) optimality conditions, we get\n\n<math>c = \\sum_{i=1}^{n}\\alpha_i\\Phi(x_i),</math>\n\nwhere the <math>\\alpha_i's</math>are the solution to the following optimization problem:\n\n<math>\\max_\\alpha \\sum_{i=1}^{n}\\alpha_i\\kappa(x_i, x_i) - \\sum_{i, j = 1}^{n}\\alpha_i\\alpha_j\\kappa(x_i, x_j)\n</math>\n\nsubject to, <math>\\sum_{i=1}^{n}\\alpha_i = 1 \\text{ and } 0 \\le \\alpha_i \\le \\frac{1}{\\nu n} \\text{for all } i = 1,2,...,n.</math>\n\nThe introduction of kernel function provide additional flexibility to the One-class [[Support-vector machine|SVM]] (OSVM) algorithm.<ref>{{Cite journal|last=Khan|first=Shehroz S.|last2=Madden|first2=Michael G.|date=2010|editor-last=Coyle|editor-first=Lorcan|editor2-last=Freyne|editor2-first=Jill|title=A Survey of Recent Trends in One Class Classification|journal=Artificial Intelligence and Cognitive Science|volume=6206|series=Lecture Notes in Computer Science|language=en|publisher=Springer Berlin Heidelberg|pages=188\u2013197|doi=10.1007/978-3-642-17080-5_21|isbn=9783642170805|hdl=10379/1472|hdl-access=free}}</ref>\n\n=== PU learning ===\nA similar problem is '''PU learning''', in which a [[binary classification|binary classifier]] is learned in a [[semi-supervised learning|semi-supervised]] way from only ''positive'' and ''unlabeled'' sample points.<ref>{{cite book|title=Web Data Mining|last=Liu|first=Bing|publisher=Springer|year=2007|pages=165\u2013178}}</ref>\n\nIn PU learning, two sets of examples are assumed to be available for training: the positive set <math>P</math> and a ''mixed set'' <math>U</math>, which is assumed to contain both positive and negative samples, but without these being labeled as such. This contrasts with other forms of semisupervised learning, where it is assumed that a labeled set containing examples of both classes is available in addition to unlabeled samples. A variety of techniques exist to adapt [[supervised learning|supervised]] classifiers to the PU learning setting, including variants of the [[Expectation-maximization|EM algorithm]]. PU learning has been successfully applied to [[text classification|text]],<ref>{{cite conference |author=Bing Liu |author2=Wee Sun Lee |author3=Philip S. Yu |author3-link=Philip S. Yu |author4=Xiao-Li Li |last-author-amp=yes |year=2002 |title=Partially supervised classification of text documents |conference=ICML |pages=8\u201312}}</ref><ref>{{cite conference |author=Hwanjo Yu |author2=Jiawei Han |author3=Kevin Chen-Chuan Chang |title=PEBL: positive example based learning for web page classification using SVM |conference=ACM SIGKDD |year=2002}}</ref><ref>{{cite conference |author=Xiao-Li Li |author2=Bing Liu |last-author-amp=yes |title=Learning to classify text using positive and unlabeled data |conference=IJCAI |year=2003}}</ref> time series,<ref>{{cite conference |author=Minh Nhut Nguyen |author2=Xiao-Li Li |author3=See-Kiong Ng |last-author-amp=yes |title=Positive Unlabeled Learning for Time Series Classification |conference=IJCAI |year=2011}}</ref> [[bioinformatics]] tasks,<ref>{{cite conference |author=Peng Yang |author2=Xiao-Li Li |author3=Jian-Ping Mei |author4=Chee-Keong Kwoh |author5=See-Kiong Ng |last-author-amp=yes |title=Positive-Unlabeled Learning for Disease Gene Identification |conference=Bioinformatics, Vol 28(20)|year=2012}}</ref> and Remote-Sensing Data.<ref>{{cite journal|last=Li|first=W.|last2=Guo|first2=Q.|last3=Elkan|first3=C.|date=February 2011|title=A Positive and Unlabeled Learning Algorithm for One-Class Classification of Remote-Sensing Data|journal=IEEE Transactions on Geoscience and Remote Sensing|volume=49|issue=2|pages=717\u2013725|doi=10.1109/TGRS.2010.2058578|issn=0196-2892}}</ref>\n\n== Approaches ==\nSeveral approaches have been proposed to solve one-class classification (OCC). The approaches can be distinguished into three main categories, '''density estimation''', '''boundary methods''', and '''reconstruction methods'''.<ref name=\":1\" />\n\n==== Density estimation methods ====\nDensity estimation methods rely on estimating the density of the data points, and set the threshold. These methods rely on assuming distributions, such as Gaussian, or a [[Poisson distribution]]. Following which discordancy tests can be used to test the new objects. These methods are robust to scale variance.\n\n'''Gaussian model'''<ref>{{Cite book|url=https://books.google.com/?id=T0S0BgAAQBAJ&pg=PP1&dq=neural+networks+for+pattern+recognition|title=Neural Networks for Pattern Recognition|last=Bishop|first=Christopher M.|last2=Bishop|first2=Professor of Neural Computing Christopher M.|date=1995-11-23|publisher=Clarendon Press|isbn=9780198538646|language=en}}</ref> is one the simplest method to create one-class classifiers. Due to Central Limit Theorem (CLT),<ref>{{Cite journal|last=R|first=Ullman Neil|date=2017-01-01|title=Elementary statistics|url=http://archives.umc.edu.dz/handle/123456789/116529}}</ref> these methods work best when large number of samples are present, and they are perturbed by small independent error values. The probability distribution for a d-dimensional object is given by:\n\n<math>p_{\\mathcal{N}}(x;\\mu;\\Sigma) = \\frac{1}{(2\\pi)^{\\frac{d}{2}} |\\Sigma|^\\frac{1}{2}}\\exp\\{-\\frac{1}{2}(z-\\mu)^T \\Sigma^{-1} (z - \\mu) \\}</math>\n\nWhere, '''<math>\\mu</math>'''is the mean and '''<math>\\Sigma </math>''' is the covariance matrix. Computing the inverse of covariance matrix ('''<math>\\Sigma^{-1}</math>''') is the costliest operation, and in the cases where the data is not scaled properly, or data has singular directions pseudo-inverse <math>\\Sigma^+</math>is used to approximate the inverse, and is calculated as <math>\\Sigma^T(\\Sigma \\Sigma^T)^{-1}</math>.<ref>{{Cite web|url=http://bookstore.siam.org/wc02/|title=Introduction to Applied Mathematics|website=SIAM Bookstore|language=en|access-date=2019-04-29}}</ref>\n\n==== Boundary methods ====\nBoundary methods focus on setting boundaries around a few set of points, called target points. These methods attempt to optimize the volume. Boundary methods rely on distances, and hence are not robust to scale variance. K-centers method, NN-d, and SVDD are some of the key examples.\n\n'''K-centers'''\n\nIn K-center algorithm,<ref>{{Cite journal|last=Ypma|first=Alexander|last2=Duin|first2=Robert P. W.|date=1998|editor-last=Niklasson|editor-first=Lars|editor2-last=Bod\u00e9n|editor2-first=Mikael|editor3-last=Ziemke|editor3-first=Tom|title=Support objects for domain approximation|journal=Icann 98|series=Perspectives in Neural Computing|language=en|publisher=Springer London|pages=719\u2013724|doi=10.1007/978-1-4471-1599-1_110|isbn=9781447115991}}</ref> <math>k</math> small balls with equal radius are placed to minimize the maximum distance of all minimum distances between training objects and the centers. Formally, the following error is minimized,\n\n<math>\\varepsilon_{k-center} = \\max_i ( \\min_k || x_i - \\mu_k ||^2 )</math>\n\nThe algorithm uses forward search method with random initialization, where the radius is determined by the maximum distance of the object, any given ball should capture. After the centers are determined, for any given test object '''<math>z</math>''' the distance can be calculated as,\n\n<math>d_{k-centr}(z) = \\min_k || z - \\mu_k ||^2</math>\n\n==== Reconstruction methods ====\nReconstruction methods use prior knowledge and generating process to build a generating model that best fits the data. New objects can be described in terms of a state of the generating model. Some examples of reconstruction methods for OCC are, k-means clustering, learning vector quantization, self-organizing maps, etc.\n\n== Applications ==\n\n=== Document classification ===\nThe basic Support Vector Machine (SVM) paradigm is trained using both positive and negative examples, however studies have shown there are many valid reasons for using ''only'' positive examples. When the SVM algorithm is modified to only use positive examples, the process is considered one-class classification. One situation where this type of classification might prove useful to the SVM paradigm is in trying to identify a web browser\u2019s sites of interest based only off of the user\u2019s browsing history.\n\n=== Biomedical studies ===\nOne-class classification can be particularly useful in biomedical studies where often data from other classes can be difficult or impossible to obtain. In studying biomedical data it can be difficult and/or expensive to obtain the set of labeled data from the second class that would be necessary to perform a two-class classification. A study from The Scientific World Journal found that the typicality approach is the most useful in analysing biomedical data because it can be applied to any type of dataset (continuous, discrete, or nominal).<ref name=\":0\">{{cite journal | vauthors = Irigoien I, Sierra B, Arenas C | title = Towards application of one-class classification methods to medical data | journal = TheScientificWorldJournal | volume = 2014 | pages = 730712 | date = 2014 | pmid = 24778600 | pmc = 3980920 | doi = 10.1155/2014/730712 }}</ref> The typicality approach is based on the clustering of data by examining data and placing it into new or existing clusters.<ref>{{cite journal | vauthors = Irigoien I, Arenas C | title = INCA: new statistic for estimating the number of clusters and identifying atypical units | journal = Statistics in Medicine | volume = 27 | issue = 15 | pages = 2948\u201373 | date = July 2008 | pmid = 18050154 | doi = 10.1002/sim.3143 }}</ref> To apply typicality to one-class classification for biomedical studies, each new observation, <math>y_0\n</math>, is compared to the target class, <math>C</math>, and identified as an outlier or a member of the target class.<ref name=\":0\" />\n\n== See also ==\n*[[Multiclass classification]]\n*[[Anomaly detection]]\n*[[Supervised learning]]\n\n== References ==\n{{reflist|30em}}\n\n[[Category:Statistical classification]]\n[[Category:Classification algorithms]]\n", "name_user": "Headbomb", "label": "safe", "comment": "\u2192\u200etop:clean up", "url_page": "//en.wikipedia.org/wiki/One-class_classification"}
