{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-3RFUG6S:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD SOME RELEVANT LIBRARIES -- OTHERS WILL BE LOADED WHEN NEEDED\n",
    "\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOP THROUGH ALL FILES\n",
    "\n",
    "import os\n",
    "rootdir = 'save/myoutput'\n",
    "\n",
    "files_list = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for name in files:\n",
    "        if \"part\" in name.lower() and not \".crc\" in name.lower():\n",
    "            files_list.append(os.path.join(subdir,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             comment| label|           name_user|            text_new|            text_old|          title_page|            url_page|\n",
      "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                    |vandal|2601:c7:c201:c160...|{{cleanup-tense|d...|{{cleanup-tense|d...|Planning of the S...|//en.wikipedia.or...|\n",
      "|      (→‎Early life)|vandal|      203.150.182.52|{{short descripti...|{{short descripti...|      John Krasinski|//en.wikipedia.or...|\n",
      "|         (→‎History)|vandal|2001:ee0:40e1:498...|{{Short descripti...|{{Short descripti...|            Nike Mag|//en.wikipedia.or...|\n",
      "|→‎Preseason All-S...|  safe|       Debartolo2917|{{short descripti...|{{short descripti...|2019 Kentucky Wil...|//en.wikipedia.or...|\n",
      "|→‎Churches:Fixing...|  safe|              BD2412|{{short descripti...|{{short descripti...|List of churches ...|//en.wikipedia.or...|\n",
      "|→‎Churches holdin...|  safe|              BD2412|[[File:StPaulsCat...|[[File:StPaulsCat...|List of churches ...|//en.wikipedia.or...|\n",
      "|            →‎Roster|  safe|       Debartolo2917|{{short descripti...|{{short descripti...|2018 Kentucky Wil...|//en.wikipedia.or...|\n",
      "|             grammar|  safe|             Znagy88|{{Infobox settlem...|{{Infobox settlem...|         Karancsalja|//en.wikipedia.or...|\n",
      "|                    |unsafe|        42.61.139.39|{{about|the actre...|{{about|the actre...|        Kim Yoo-jung|//en.wikipedia.or...|\n",
      "|- 5 categories us...|  safe|          Richhoncho|{{other uses}}\n",
      "{{...|{{other uses}}\n",
      "{{...|         Peter Piper|//en.wikipedia.or...|\n",
      "|→‎Bibliography:am...|  safe|              FDW777|{{redirect|PIRA}}...|{{redirect|PIRA}}...|Provisional Irish...|//en.wikipedia.or...|\n",
      "|Fixed citation an...|  safe|             Nempnet|{{Use dmy dates|d...|{{Use dmy dates|d...|Caledonian Railwa...|//en.wikipedia.or...|\n",
      "|→‎Appearances in ...|  safe|          Nedrutland|{{Ibid|date=Augus...|{{Ibid|date=Augus...|Department of Ang...|//en.wikipedia.or...|\n",
      "|  →‎Season 17 (2020)|  safe|               Eriru|{{short descripti...|{{short descripti...|List of Ridiculou...|//en.wikipedia.or...|\n",
      "|                    |  safe|           Happyomen|{{Infobox artist ...|{{Infobox artist ...|Band of Horses di...|//en.wikipedia.or...|\n",
      "|external link rem...|  safe|             Manatoc|{{Infobox musical...|{{Infobox musical...|         Todd Tobias|//en.wikipedia.or...|\n",
      "|          →‎Examples|  safe|          Artoria2e5|{{lowercase|title...|{{lowercase|title...|               Xargs|//en.wikipedia.or...|\n",
      "|→‎top:replaced: A...|  safe|   Chris the speller|{{Short descripti...|{{Short descripti...| James T. Vaughn Jr.|//en.wikipedia.or...|\n",
      "|                    |  safe|       Dangerousalex|{{Infobox album\n",
      "|...|{{Infobox album\n",
      "|...|Sexorcism (Brooke...|//en.wikipedia.or...|\n",
      "|(Reverted 1 edit ...|unsafe|         Classicwiki|{{short descripti...|{{short descripti...|Constitutional mo...|//en.wikipedia.or...|\n",
      "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PUT ALL FILES TO ONE JSON DATAFRAME\n",
    "\n",
    "df = spark.read.json(sc.textFile(','.join(files_list)))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- comment: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- name_user: string (nullable = true)\n",
      " |-- text_new: string (nullable = true)\n",
      " |-- text_old: string (nullable = true)\n",
      " |-- title_page: string (nullable = true)\n",
      " |-- url_page: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SHOW SCHEMA OF THE DATASET\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "| label|count|\n",
      "+------+-----+\n",
      "|  safe| 1405|\n",
      "|unsafe|  233|\n",
      "|vandal|   27|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DISTRIBUTION OF LABELS IN THE DATASET\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "df.groupBy(\"label\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO SAMPLE FROM DATAFRAME (USE SAMPLEBY TO SPECIFY SAMPLED FRACTIONS OF EACH CLASS)\n",
    "#import pyspark.sql\n",
    "#df_sample = df.sample(False, fraction = 0.1, seed = 100)\n",
    "#df_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             comment| label|           name_user|            text_new|            text_old|          title_page|            url_page|          difference|\n",
      "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                    |vandal|2601:c7:c201:c160...|{{cleanup-tense|d...|{{cleanup-tense|d...|Planning of the S...|//en.wikipedia.or...|aFollow me o tikt...|\n",
      "|      (→‎Early life)|vandal|      203.150.182.52|{{short descripti...|{{short descripti...|      John Krasinski|//en.wikipedia.or...|       he is amazing|\n",
      "|         (→‎History)|vandal|2001:ee0:40e1:498...|{{Short descripti...|{{Short descripti...|            Nike Mag|//en.wikipedia.or...|. and it's so stu...|\n",
      "|→‎Preseason All-S...|  safe|       Debartolo2917|{{short descripti...|{{short descripti...|2019 Kentucky Wil...|//en.wikipedia.or...|                 Jr.|\n",
      "|→‎Churches:Fixing...|  safe|              BD2412|{{short descripti...|{{short descripti...|List of churches ...|//en.wikipedia.or...|       Augustinians||\n",
      "|→‎Churches holdin...|  safe|              BD2412|[[File:StPaulsCat...|[[File:StPaulsCat...|List of churches ...|//en.wikipedia.or...|                   s|\n",
      "|            →‎Roster|  safe|       Debartolo2917|{{short descripti...|{{short descripti...|2018 Kentucky Wil...|//en.wikipedia.or...|      Jr. Jr.|link=y|\n",
      "|             grammar|  safe|             Znagy88|{{Infobox settlem...|{{Infobox settlem...|         Karancsalja|//en.wikipedia.or...|must s probably b...|\n",
      "|                    |unsafe|        42.61.139.39|{{about|the actre...|{{about|the actre...|        Kim Yoo-jung|//en.wikipedia.or...|                  39|\n",
      "|- 5 categories us...|  safe|          Richhoncho|{{other uses}}\n",
      "{{...|{{other uses}}\n",
      "{{...|         Peter Piper|//en.wikipedia.or...|English-language ...|\n",
      "|→‎Bibliography:am...|  safe|              FDW777|{{redirect|PIRA}}...|{{redirect|PIRA}}...|Provisional Irish...|//en.wikipedia.or...|| last = Coogan |...|\n",
      "|Fixed citation an...|  safe|             Nempnet|{{Use dmy dates|d...|{{Use dmy dates|d...|Caledonian Railwa...|//en.wikipedia.or...|                   t|\n",
      "|→‎Appearances in ...|  safe|          Nedrutland|{{Ibid|date=Augus...|{{Ibid|date=Augus...|Department of Ang...|//en.wikipedia.or...|            (2009)y'|\n",
      "|  →‎Season 17 (2020)|  safe|               Eriru|{{short descripti...|{{short descripti...|List of Ridiculou...|//en.wikipedia.or...|0.27<ref>{{cite w...|\n",
      "|                    |  safe|           Happyomen|{{Infobox artist ...|{{Infobox artist ...|Band of Horses di...|//en.wikipedia.or...|[[enmark|IFPI D]]...|\n",
      "|external link rem...|  safe|             Manatoc|{{Infobox musical...|{{Infobox musical...|         Todd Tobias|//en.wikipedia.or...|  Italian vocalis...|\n",
      "|          →‎Examples|  safe|          Artoria2e5|{{lowercase|title...|{{lowercase|title...|               Xargs|//en.wikipedia.or...|                  \n",
      "\n",
      "|\n",
      "|→‎top:replaced: A...|  safe|   Chris the speller|{{Short descripti...|{{Short descripti...| James T. Vaughn Jr.|//en.wikipedia.or...|      AssocissociaJj|\n",
      "|                    |  safe|       Dangerousalex|{{Infobox album\n",
      "|...|{{Infobox album\n",
      "|...|Sexorcism (Brooke...|//en.wikipedia.or...|                [[]]|\n",
      "|(Reverted 1 edit ...|unsafe|         Classicwiki|{{short descripti...|{{short descripti...|Constitutional mo...|//en.wikipedia.or...|                 n a|\n",
      "+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DIFFERENCE BETWEEN OLD AND NEW TEXT\n",
    "\n",
    "import difflib\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def make_diff(old, new):\n",
    "    diff = difflib.ndiff(old, new)\n",
    "    delta = ''.join(x[2:] for x in diff if x.startswith('- ') or x.startswith('+'))\n",
    "    return delta\n",
    "\n",
    "#convert to a UDF Function and get difference between columns\n",
    "udfmake_diff = F.udf(make_diff, StringType())\n",
    "df_difference = df.withColumn(\"difference\", lit(udfmake_diff(\"text_old\", \"text_new\")))\n",
    "df_difference.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE COLUMN NAME FROM 'LABEL' TO 'LABEL_STRING' -- LATER WE WILL CONVERT LABEL_STRING TO NUMERICAL VALUES AND GIVE THE COLUMN NAME 'LABEL'\n",
    "\n",
    "df_wd = df_difference.withColumnRenamed('label', 'label_string')\n",
    "#df_wd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##\n",
    "## NOTE !!!!!!\n",
    "##\n",
    "## CHOOSE TO RUN ONLY ONE OF THE FOLLOWING TWO CELLS\n",
    "## DO NOT RUN THEM BOTH\n",
    "##\n",
    "##\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 1175\n",
      "Test Dataset Count: 490\n",
      "Distribution of labels in train set:\n",
      "+------------+-----+\n",
      "|label_string|count|\n",
      "+------------+-----+\n",
      "|        safe|  995|\n",
      "|      unsafe|  161|\n",
      "|      vandal|   19|\n",
      "+------------+-----+\n",
      "\n",
      "Distribution of labels in test set:\n",
      "+------------+-----+\n",
      "|label_string|count|\n",
      "+------------+-----+\n",
      "|        safe|  410|\n",
      "|      unsafe|   72|\n",
      "|      vandal|    8|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EITHER RUN THIS CELL OR THE NEXT CELL (BUT NOT BOTH)\n",
    "# THIS IS RUN ONLY TO TEST MODEL ACCURACY AND TUNE THE MODEL -- SKIP TO TRAIN MODEL ON THE WHOLE DATASET\n",
    "\n",
    "# split dataset to train and test sets\n",
    "\n",
    "(trainingData, testData) = df_wd.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))\n",
    "\n",
    "\n",
    "print(\"Distribution of labels in train set:\")\n",
    "trainingData.groupBy(\"label_string\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()\n",
    "\n",
    "print(\"Distribution of labels in test set:\")\n",
    "testData.groupBy(\"label_string\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EITHER RUN THIS CELL OR THE CELL ABOVE (BUT NOT BOTH)\n",
    "# THIS IS RUN TO TRAIN SELECTED MODEL ON THE ENTIRE DATASET\n",
    "\n",
    "trainingData = df_wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTE NaN'S INSTEAD OF EMPTY STRINGS\n",
    "\n",
    "#def processMissingCategory(s):\n",
    "#    if s == \"\":\n",
    "#        return \"NaN\"\n",
    "#    else:\n",
    "#        return s\n",
    "\n",
    "#udfprocessMissingCategory = F.udf(processMissingCategory, StringType())\n",
    "#df_nona = df_difference.withColumn('comment', lit(udfprocessMissingCategory('comment')))\n",
    "#df_nona.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZING 'DIFFERENCE' COLUMN AND REMOVING CERTAIN STOP WORDS\n",
    "\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "\n",
    "# tokenize 'difference' column\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"difference\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "regexTokenizer_comment = RegexTokenizer(inputCol=\"comment\", outputCol=\"words_comment\", pattern=\"\\\\W\")\n",
    "\n",
    "# remove stop words\n",
    "stop_words = [\"http\",\"https\", \"a\", \"an\", \"the\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"and\", \"any\", \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\",\n",
    "              \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \"doing\", \n",
    "              \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\",\n",
    "              \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\",\n",
    "              \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\",\n",
    "              \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\",\n",
    "              \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\",\n",
    "              \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\",\n",
    "              \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"won't\",\n",
    "              \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"] \n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(stop_words)\n",
    "stopwordsRemover_comment = StopWordsRemover(inputCol=\"words_comment\", outputCol=\"filtered_comment\").setStopWords(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT 'LABEL_STRING' TO NUMERIC COLUMN 'LABEL'\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "# index categorical variable\n",
    "label_stringIdx = StringIndexer(inputCol = \"label_string\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##\n",
    "## NOTE !!!!!!\n",
    "##\n",
    "## CHOOSE TO RUN ONLY ONE OF THE FOLLOWING TWO CELLS\n",
    "## DO NOT RUN THEM BOTH\n",
    "##\n",
    "##\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF AND PIPELINE -- WITHOUT 'COMMENT'\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# do TF-IDF embeding\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF AND PIPELINE -- WITH 'COMMENT'\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# do TF-IDF embeding\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features_diff\")\n",
    "\n",
    "hashingTF_comment = HashingTF(inputCol=\"filtered_comment\", outputCol=\"rawFeatures_comment\", numFeatures=10000)\n",
    "idf_comment = IDF(inputCol=\"rawFeatures_comment\", outputCol=\"features_comment\")\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"features_comment\", \"features_diff\"], outputCol=\"features\")\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, regexTokenizer_comment, stopwordsRemover, stopwordsRemover_comment, hashingTF, hashingTF_comment, idf, idf_comment, \n",
    "                            assembler, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT PIPELINE ON TRAIN DATASET\n",
    "\n",
    "pipelineFit = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE PIPELINE\n",
    "\n",
    "#outpath = 'models/without_comment/tfidf'\n",
    "#outpath = 'models/with_comment/tfidf'\n",
    "outpath = 'models/best/tfidf'\n",
    "pipelineFit.write().overwrite().save(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|          difference|               words|            filtered|         rawFeatures|       features_diff|label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|aFollow me o tikt...|[afollow, me, o, ...|[afollow, o, tikt...|(10000,[613,763,2...|(10000,[613,763,2...|  2.0|\n",
      "|       he is amazing|   [he, is, amazing]|           [amazing]|(10000,[9258],[1.0])|(10000,[9258],[5....|  2.0|\n",
      "|. and it's so stu...|[and, it, s, so, ...|         [s, stupid]|(10000,[2197,9121...|(10000,[2197,9121...|  2.0|\n",
      "|                 Jr.|                [jr]|                [jr]|(10000,[9896],[1.0])|(10000,[9896],[5....|  0.0|\n",
      "|       Augustinians||      [augustinians]|      [augustinians]|(10000,[2223],[1.0])|(10000,[2223],[4....|  0.0|\n",
      "|                   s|                 [s]|                 [s]|(10000,[2197],[1.0])|(10000,[2197],[2....|  0.0|\n",
      "|      Jr. Jr.|link=y|   [jr, jr, link, y]|   [jr, jr, link, y]|(10000,[4315,5066...|(10000,[4315,5066...|  0.0|\n",
      "|must s probably b...|[must, s, probabl...|[must, s, probabl...|(10000,[1,502,585...|(10000,[1,502,585...|  0.0|\n",
      "|                  39|                [39]|                [39]|(10000,[3167],[1.0])|(10000,[3167],[5....|  1.0|\n",
      "|English-language ...|[english, languag...|[english, languag...|(10000,[974,1101,...|(10000,[974,1101,...|  0.0|\n",
      "|| last = Coogan |...|[last, coogan, fi...|[last, coogan, fi...|(10000,[372,393,5...|(10000,[372,393,5...|  0.0|\n",
      "|                   t|                 [t]|                 [t]|(10000,[7777],[1.0])|(10000,[7777],[3....|  0.0|\n",
      "|            (2009)y'|           [2009, y]|           [2009, y]|(10000,[458,4315]...|(10000,[458,4315]...|  0.0|\n",
      "|0.27<ref>{{cite w...|[0, 27, ref, cite...|[0, 27, ref, cite...|(10000,[419,524,5...|(10000,[419,524,5...|  0.0|\n",
      "|[[enmark|IFPI D]]...|[enmark, ifpi, d,...|[enmark, ifpi, d,...|(10000,[918,1958,...|(10000,[918,1958,...|  0.0|\n",
      "|  Italian vocalis...|[italian, vocalis...|[italian, vocalis...|(10000,[372,2416,...|(10000,[372,2416,...|  0.0|\n",
      "|                  \n",
      "\n",
      "|                  []|                  []|       (10000,[],[])|       (10000,[],[])|  0.0|\n",
      "|      AssocissociaJj|    [associssociajj]|    [associssociajj]|(10000,[6981],[1.0])|(10000,[6981],[6....|  0.0|\n",
      "|                [[]]|                  []|                  []|       (10000,[],[])|       (10000,[],[])|  0.0|\n",
      "|                 n a|              [n, a]|                 [n]|(10000,[1655],[1.0])|(10000,[1655],[3....|  1.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|             comment|       words_comment|    filtered_comment| rawFeatures_comment|    features_comment|label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|                    |                  []|                  []|       (10000,[],[])|       (10000,[],[])|  2.0|\n",
      "|      (→‎Early life)|       [early, life]|       [early, life]|(10000,[3477,4372...|(10000,[3477,4372...|  2.0|\n",
      "|         (→‎History)|           [history]|           [history]|(10000,[4293],[1.0])|(10000,[4293],[4....|  2.0|\n",
      "|→‎Preseason All-S...|[preseason, all, ...|[preseason, sec, ...|(10000,[1317,3521...|(10000,[1317,3521...|  0.0|\n",
      "|→‎Churches:Fixing...|[churches, fixing...|[churches, fixing...|(10000,[20,650,28...|(10000,[20,650,28...|  0.0|\n",
      "|→‎Churches holdin...|[churches, holdin...|[churches, holdin...|(10000,[20,650,22...|(10000,[20,650,22...|  0.0|\n",
      "|            →‎Roster|            [roster]|            [roster]|(10000,[2066],[1.0])|(10000,[2066],[6....|  0.0|\n",
      "|             grammar|           [grammar]|           [grammar]|(10000,[7669],[1.0])|(10000,[7669],[4....|  0.0|\n",
      "|                    |                  []|                  []|       (10000,[],[])|       (10000,[],[])|  1.0|\n",
      "|- 5 categories us...|[5, categories, u...|[5, categories, u...|(10000,[704,1169,...|(10000,[704,1169,...|  0.0|\n",
      "|→‎Bibliography:am...|[bibliography, am...|[bibliography, am...|(10000,[1718,4690...|(10000,[1718,4690...|  0.0|\n",
      "|Fixed citation an...|[fixed, citation,...|[fixed, citation,...|(10000,[3712,5577...|(10000,[3712,5577...|  0.0|\n",
      "|→‎Appearances in ...|[appearances, in,...|[appearances, pop...|(10000,[320,4692,...|(10000,[320,4692,...|  0.0|\n",
      "|  →‎Season 17 (2020)|  [season, 17, 2020]|  [season, 17, 2020]|(10000,[4091,5210...|(10000,[4091,5210...|  0.0|\n",
      "|                    |                  []|                  []|       (10000,[],[])|       (10000,[],[])|  0.0|\n",
      "|external link rem...|[external, link, ...|[external, link, ...|(10000,[586,1512,...|(10000,[586,1512,...|  0.0|\n",
      "|          →‎Examples|          [examples]|          [examples]|(10000,[1350],[1.0])|(10000,[1350],[6....|  0.0|\n",
      "|→‎top:replaced: A...|[top, replaced, a...|[top, replaced, a...|(10000,[20,4441,6...|(10000,[20,4441,6...|  0.0|\n",
      "|                    |                  []|                  []|       (10000,[],[])|       (10000,[],[])|  0.0|\n",
      "|(Reverted 1 edit ...|[reverted, 1, edi...|[reverted, 1, edi...|(10000,[658,1219,...|(10000,[658,1219,...|  1.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+--------------------+-----+\n",
      "|       features_diff|    features_comment|            features|label|\n",
      "+--------------------+--------------------+--------------------+-----+\n",
      "|(10000,[613,763,2...|       (10000,[],[])|(20000,[10613,107...|  2.0|\n",
      "|(10000,[9258],[5....|(10000,[3477,4372...|(20000,[3477,4372...|  2.0|\n",
      "|(10000,[2197,9121...|(10000,[4293],[4....|(20000,[4293,1219...|  2.0|\n",
      "|(10000,[9896],[5....|(10000,[1317,3521...|(20000,[1317,3521...|  0.0|\n",
      "|(10000,[2223],[4....|(10000,[20,650,28...|(20000,[20,650,28...|  0.0|\n",
      "|(10000,[2197],[2....|(10000,[20,650,22...|(20000,[20,650,22...|  0.0|\n",
      "|(10000,[4315,5066...|(10000,[2066],[6....|(20000,[2066,1431...|  0.0|\n",
      "|(10000,[1,502,585...|(10000,[7669],[4....|(20000,[7669,1000...|  0.0|\n",
      "|(10000,[3167],[5....|       (10000,[],[])|(20000,[13167],[5...|  1.0|\n",
      "|(10000,[974,1101,...|(10000,[704,1169,...|(20000,[704,1169,...|  0.0|\n",
      "|(10000,[372,393,5...|(10000,[1718,4690...|(20000,[1718,4690...|  0.0|\n",
      "|(10000,[7777],[3....|(10000,[3712,5577...|(20000,[3712,5577...|  0.0|\n",
      "|(10000,[458,4315]...|(10000,[320,4692,...|(20000,[320,4692,...|  0.0|\n",
      "|(10000,[419,524,5...|(10000,[4091,5210...|(20000,[4091,5210...|  0.0|\n",
      "|(10000,[918,1958,...|       (10000,[],[])|(20000,[10918,119...|  0.0|\n",
      "|(10000,[372,2416,...|(10000,[586,1512,...|(20000,[586,1512,...|  0.0|\n",
      "|       (10000,[],[])|(10000,[1350],[6....|(20000,[1350],[6....|  0.0|\n",
      "|(10000,[6981],[6....|(10000,[20,4441,6...|(20000,[20,4441,6...|  0.0|\n",
      "|       (10000,[],[])|       (10000,[],[])|       (20000,[],[])|  0.0|\n",
      "|(10000,[1655],[3....|(10000,[658,1219,...|(20000,[658,1219,...|  1.0|\n",
      "+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# USE PIPELINE ON TRAIN DATASET\n",
    "\n",
    "dataset_tr = pipelineFit.transform(trainingData)\n",
    "\n",
    "# without 'comment':\n",
    "#dataset_tr.select(\"difference\",\"words\",\"filtered\",\"rawFeatures\",\"features\", \"label\").show()\n",
    "\n",
    "# with 'comment':\n",
    "dataset_tr.select(\"difference\",\"words\",\"filtered\",\"rawFeatures\",\"features_diff\", \"label\").show()\n",
    "dataset_tr.select(\"comment\",\"words_comment\",\"filtered_comment\",\"rawFeatures_comment\",\"features_comment\", \"label\").show()\n",
    "dataset_tr.select(\"features_diff\", \"features_comment\", \"features\", \"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+\n",
      "|       features_diff|    features_comment|            features|label|\n",
      "+--------------------+--------------------+--------------------+-----+\n",
      "|(10000,[9896],[5....|(10000,[1317,3521...|(20000,[1317,3521...|  0.0|\n",
      "|(10000,[4315,5066...|(10000,[2066],[5....|(20000,[2066,1431...|  0.0|\n",
      "|(10000,[1,502,585...|(10000,[7669],[4....|(20000,[7669,1000...|  0.0|\n",
      "|(10000,[918,1958,...|       (10000,[],[])|(20000,[10918,119...|  0.0|\n",
      "|       (10000,[],[])|(10000,[1350],[6....|(20000,[1350],[6....|  0.0|\n",
      "|(10000,[1655],[3....|(10000,[658,1219,...|(20000,[658,1219,...|  1.0|\n",
      "|(10000,[524,2710,...|(10000,[1636,2709...|(20000,[1636,2709...|  1.0|\n",
      "|(10000,[98,174,20...|(10000,[4058,6469...|(20000,[4058,6469...|  1.0|\n",
      "|(10000,[839],[6.3...|       (10000,[],[])|(20000,[10839],[6...|  0.0|\n",
      "|       (10000,[],[])|(10000,[3624,3773...|(20000,[3624,3773...|  0.0|\n",
      "|(10000,[2223],[4....|(10000,[20,650,28...|(20000,[20,650,28...|  0.0|\n",
      "|(10000,[2197,2804...|(10000,[20,650,28...|(20000,[20,650,28...|  0.0|\n",
      "|(10000,[2197,4529...|(10000,[20,650,17...|(20000,[20,650,17...|  0.0|\n",
      "|(10000,[695,5442,...|(10000,[1384,5734...|(20000,[1384,5734...|  0.0|\n",
      "|(10000,[2197,2804...|(10000,[20,650,28...|(20000,[20,650,28...|  0.0|\n",
      "|(10000,[2825,5003...|(10000,[2825,2900...|(20000,[2825,2900...|  0.0|\n",
      "|(10000,[7961],[7....|(10000,[8817],[5....|(20000,[8817,1796...|  0.0|\n",
      "|(10000,[2896,6435...|(10000,[982],[7.0...|(20000,[982,12896...|  0.0|\n",
      "|(10000,[7777],[3....|(10000,[3712,5577...|(20000,[3712,5577...|  0.0|\n",
      "|       (10000,[],[])|(10000,[6716,9462...|(20000,[6716,9462...|  0.0|\n",
      "+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# USE PIPELINE ON TEST DATASET (ONLY DO IF THE SPLIT BETWEEN TRAIN AND TEST SETS WAS PERFORMED)\n",
    "\n",
    "dataset_test = pipelineFit.transform(testData)\n",
    "\n",
    "# without 'comment':\n",
    "#dataset_test.select(\"difference\",\"words\",\"filtered\",\"rawFeatures\",\"features\", \"label\").show()\n",
    "\n",
    "# with 'comment':\n",
    "#dataset_test.select(\"difference\",\"words\",\"filtered\",\"rawFeatures\",\"features_diff\", \"label\").show()\n",
    "#dataset_test.select(\"comment\",\"words_comment\",\"filtered_comment\",\"rawFeatures_comment\",\"features_comment\", \"label\").show()\n",
    "dataset_test.select(\"features_diff\", \"features_comment\", \"features\", \"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE WILL USE LOGISTIC REGRESSION FOR PREDICTING\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##\n",
    "## NOTE !!!!!!\n",
    "##\n",
    "## THE FOLLOWING PART IS FOR TESTING MODEL ACCURACY, MODEL TUNING AND DECIDING WHICH MODEL TO USE\n",
    "## USE IT ONLY IF YOU SPLIT INITIAL DATASET TO TRAIN AND TEST SETS\n",
    "## IN ORDER TO USE THE WHOLE DATASET AND TRAIN THE FINAL MODEL, SKIP UNTIL THE NEXT NOTICE\n",
    "##\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+--------------------+-----+----------+\n",
      "|             comment|          difference|label_string|         probability|label|prediction|\n",
      "+--------------------+--------------------+------------+--------------------+-----+----------+\n",
      "|                    |aFollow me o tikt...|      vandal|[2.99336024484039...|  2.0|       2.0|\n",
      "|      (→‎Early life)|       he is amazing|      vandal|[1.01905124206611...|  2.0|       2.0|\n",
      "|         (→‎History)|. and it's so stu...|      vandal|[2.24233585579803...|  2.0|       2.0|\n",
      "|→‎Churches:Fixing...|       Augustinians||        safe|[0.99999999999998...|  0.0|       0.0|\n",
      "|→‎Churches holdin...|                   s|        safe|[0.99999999999999...|  0.0|       0.0|\n",
      "|                    |                  39|      unsafe|[0.11500521988558...|  1.0|       1.0|\n",
      "|- 5 categories us...|English-language ...|        safe|[1.0,7.9248811491...|  0.0|       0.0|\n",
      "|→‎Bibliography:am...|| last = Coogan |...|        safe|[1.0,1.5942424785...|  0.0|       0.0|\n",
      "|Fixed citation an...|                   t|        safe|[0.99999999990135...|  0.0|       0.0|\n",
      "|→‎Appearances in ...|            (2009)y'|        safe|[0.99999999999553...|  0.0|       0.0|\n",
      "|  →‎Season 17 (2020)|0.27<ref>{{cite w...|        safe|[1.0,1.0737787628...|  0.0|       0.0|\n",
      "|external link rem...|  Italian vocalis...|        safe|[1.0,1.3328778223...|  0.0|       0.0|\n",
      "|→‎top:replaced: A...|      AssocissociaJj|        safe|[0.99999999999990...|  0.0|       0.0|\n",
      "|                    |                [[]]|        safe|[0.97385631405856...|  0.0|       0.0|\n",
      "|                    |         1720|df=yes|        safe|[0.99999970334339...|  0.0|       0.0|\n",
      "|            →‎Roster|          Jr.|link=y|        safe|[0.99999999964815...|  0.0|       0.0|\n",
      "|→‎Rodnover spirit...|        21twenty-fir|        safe|[0.99999999999996...|  0.0|       0.0|\n",
      "|                    |<br>This is unlik...|        safe|[0.99999999999999...|  0.0|       0.0|\n",
      "|(→‎Film and telev...|}}</ref>\n",
      "* ''West...|      unsafe|[2.94520049546169...|  1.0|       1.0|\n",
      "|    →‎Chondrichthyes|\n",
      "|-\n",
      "|}\n",
      "\n",
      "====Sarco...|        safe|[1.0,6.4652595152...|  0.0|       0.0|\n",
      "+--------------------+--------------------+------------+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION WITHOUT WEIGHTS\n",
    "\n",
    "# fit logistic regression\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=20)\n",
    "lrModel = lr.fit(dataset_tr)\n",
    "\n",
    "\n",
    "# predict train set\n",
    "predict_train = lrModel.transform(dataset_tr)\n",
    "predict_train.select(\"comment\", \"difference\",\"label_string\",\"probability\",\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+--------------------+-----+----------+\n",
      "|             comment|          difference|label_string|         probability|label|prediction|\n",
      "+--------------------+--------------------+------------+--------------------+-----+----------+\n",
      "|→‎Preseason All-S...|                 Jr.|        safe|[0.99999999999792...|  0.0|       0.0|\n",
      "|            →‎Roster|      Jr. Jr.|link=y|        safe|[0.99999999989095...|  0.0|       0.0|\n",
      "|             grammar|must s probably b...|        safe|[0.99999949923676...|  0.0|       0.0|\n",
      "|                    |[[enmark|IFPI D]]...|        safe|[3.40668019160156...|  0.0|       1.0|\n",
      "|          →‎Examples|                  \n",
      "\n",
      "|        safe|[0.99347251932481...|  0.0|       0.0|\n",
      "|(Reverted 1 edit ...|                 n a|      unsafe|[0.96886453107520...|  1.0|       0.0|\n",
      "|(reference is ina...|>|ref1=<ref>https...|      unsafe|[0.99999999207570...|  1.0|       0.0|\n",
      "|(→‎Other famous B...|\n",
      "* [[Kemal Reis]]...|      unsafe|[1.03681996028575...|  1.0|       1.0|\n",
      "|                    |    MaySeptember1820|        safe|[0.44504905446088...|  0.0|       1.0|\n",
      "|dashes, fixed usi...|                  -–|        safe|[0.99999999999999...|  0.0|       0.0|\n",
      "|→‎top:Fixinglinks...|       Augustinians||        safe|[0.99999999999999...|  0.0|       0.0|\n",
      "|→‎top:Fixinglinks...|       s|Augustinian|        safe|[0.99999999999999...|  0.0|       0.0|\n",
      "|→‎Museums:Fixingl...|s|AugustinianAugu...|        safe|[1.0,1.7424354718...|  0.0|       0.0|\n",
      "| Added other authors||Baxter|MitchellB...|        safe|[0.99999858771877...|  0.0|       0.0|\n",
      "|→‎History:Fixingl...|       s|Augustinian|        safe|[0.99999999999993...|  0.0|       0.0|\n",
      "|+Marshal (2019 fi...|film)|''Marshal''...|        safe|[1.0,1.1638268880...|  0.0|       0.0|\n",
      "|             special|         sphighrcial|        safe|[0.99999989985118...|  0.0|       0.0|\n",
      "|              layout|upright=0.75|upri...|        safe|[6.91126012921367...|  0.0|       1.0|\n",
      "|Fixed citation an...|                   t|        safe|[0.99999999990135...|  0.0|       0.0|\n",
      "|→‎Returning starters|                [[]]|        safe|[0.99775228709119...|  0.0|       0.0|\n",
      "+--------------------+--------------------+------------+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict test set\n",
    "\n",
    "predict_test = lrModel.transform(dataset_test)\n",
    "predict_test.select(\"comment\", \"difference\",\"label_string\",\"probability\",\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE LOGISTIC REGRESSION WITHOUT WEIGHTS\n",
    "\n",
    "#outpath = 'models/without_comment/logistic_regression'\n",
    "#outpath = 'models/with_comment/logistic_regression'\n",
    "\n",
    "#lrModel.write().overwrite().save(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LOGISTIC REGRESSION WITHOUT WEIGHTS\n",
    "\n",
    "#from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "#LogisticRegressionModel.load('models/without_comment/logistic_regression')\n",
    "#LogisticRegressionModel.load('models/with_comment/logistic_regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy train set: 0.9948936170212765\n",
      "overall accuracy test set: 0.8061224489795918\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE OVERALL MODEL ACCURACY FOR TRAIN AND TEST SETS\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol = \"label\", metricName=\"accuracy\")\n",
    "\n",
    "print(\"overall accuracy train set: %s\" % (evaluator.evaluate(predict_train)))\n",
    "print(\"overall accuracy test set: %s\" % (evaluator.evaluate(predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for label 0 (safe): 0.9979899497487437\n",
      "training accuracy for label 1 (unsafe): 0.9751552795031055\n",
      "training accuracy for label 2 (vandal): 1.0\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE MODEL ACCURACY FOR TRAIN SET BY LABEL\n",
    "\n",
    "zeros = predict_train.where(\"label == 0\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 0 (safe): %s\" % (evaluator.evaluate(zeros)))\n",
    "\n",
    "ones = predict_train.where(\"label == 1\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 1 (unsafe): %s\" % (evaluator.evaluate(ones)))\n",
    "\n",
    "twos = predict_train.where(\"label == 2\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 2 (vandal): %s\" % (evaluator.evaluate(twos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for label 0 (safe): 0.9073170731707317\n",
      "training accuracy for label 1 (unsafe): 0.3194444444444444\n",
      "training accuracy for label 2 (vandal): 0.0\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE MODEL ACCURACY FOR TEST SET BY LABEL\n",
    "\n",
    "zeros_test = predict_test.where(\"label == 0\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 0 (safe): %s\" % (evaluator.evaluate(zeros_test)))\n",
    "\n",
    "ones_test = predict_test.where(\"label == 1\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 1 (unsafe): %s\" % (evaluator.evaluate(ones_test)))\n",
    "\n",
    "twos_test = predict_test.where(\"label == 2\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 2 (vandal): %s\" % (evaluator.evaluate(twos_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTICS ON TRAINING DATA\n",
    "\n",
    "#trainingSummary = lrModel.summary\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "#print(\"False positive rate by label:\")\n",
    "#for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "#    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "#print(\"True positive rate by label:\")\n",
    "#for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "#    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "#print(\"Precision by label:\")\n",
    "#for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "#    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "#print(\"Recall by label:\")\n",
    "#for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "#    print(\"label %d: %s\" % (i, rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of 0s is 0.8468085106382979\n",
      "The percentage of 1s is 0.13702127659574467\n",
      "The percentage of 2s is 0.016170212765957426\n",
      "The weight of class safe is 1.1809045226130652\n",
      "The weight of class unsafe is 7.2981366459627335\n",
      "The weight of class vandal is 61.842105263157976\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION WITH WEIGHTS -- CALCULATING WEIGHTS\n",
    "\n",
    "dataset_tr_size = float(dataset_tr.select(\"label\").count())\n",
    "\n",
    "numZeros = dataset_tr.select(\"label\").where('label == 0').count()\n",
    "perZeros = (float(numZeros)/float(dataset_tr_size))\n",
    "\n",
    "numOnes = dataset_tr.select(\"label\").where('label == 1').count()\n",
    "perOnes = (float(numOnes)/float(dataset_tr_size))\n",
    "\n",
    "perTwos = 1-perOnes-perZeros\n",
    "\n",
    "print('The percentage of 0s is {}'.format(perZeros))\n",
    "print('The percentage of 1s is {}'.format(perOnes))\n",
    "print('The percentage of 2s is {}'.format(perTwos))\n",
    "\n",
    "weight0 = 1/(perZeros)\n",
    "weight1 = 1/(perOnes)\n",
    "weight2 = 1/(perTwos)\n",
    "\n",
    "print('The weight of class safe is {}'.format(weight0))\n",
    "print('The weight of class unsafe is {}'.format(weight1))\n",
    "print('The weight of class vandal is {}'.format(weight2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|label|      classWeights|\n",
      "+-----+------------------+\n",
      "|  2.0|61.842105263157976|\n",
      "|  2.0|61.842105263157976|\n",
      "|  2.0|61.842105263157976|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  1.0|7.2981366459627335|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  0.0|1.1809045226130652|\n",
      "|  1.0|7.2981366459627335|\n",
      "|  0.0|1.1809045226130652|\n",
      "+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION WITH WEIGHTS -- ADDING WEIGHT COLUMN\n",
    "\n",
    "dataset_tr = dataset_tr.withColumn(\"classWeights\", F.when(dataset_tr.label == 0, weight0).when(dataset_tr.label == 1, weight1).otherwise(weight2))\n",
    "dataset_tr.select(\"label\",\"classWeights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION WITH WEIGHTS -- TRAINING AND PREDICTING\n",
    "\n",
    "lr_w = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", weightCol=\"classWeights\", maxIter=20)\n",
    "lrModel_w = lr_w.fit(dataset_tr)\n",
    "\n",
    "predict_train_w = lrModel_w.transform(dataset_tr)\n",
    "predict_test_w = lrModel_w.transform(dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+-----+----------+\n",
      "|          difference|label_string|         probability|label|prediction|\n",
      "+--------------------+------------+--------------------+-----+----------+\n",
      "|aFollow me o tikt...|      vandal|[5.63891087403971...|  2.0|       2.0|\n",
      "|       he is amazing|      vandal|[4.43415628387741...|  2.0|       2.0|\n",
      "|. and it's so stu...|      vandal|[1.80586963405488...|  2.0|       2.0|\n",
      "|       Augustinians||        safe|[0.99999999999998...|  0.0|       0.0|\n",
      "|                   s|        safe|[0.99999999999999...|  0.0|       0.0|\n",
      "|                  39|      unsafe|[7.02211183997095...|  1.0|       1.0|\n",
      "|English-language ...|        safe|[0.99999999988305...|  0.0|       0.0|\n",
      "|| last = Coogan |...|        safe|[0.99999952591428...|  0.0|       0.0|\n",
      "|                   t|        safe|[0.99999999997636...|  0.0|       0.0|\n",
      "|            (2009)y'|        safe|[0.99999999999999...|  0.0|       0.0|\n",
      "|0.27<ref>{{cite w...|        safe|[0.99999999999999...|  0.0|       0.0|\n",
      "|  Italian vocalis...|        safe|[0.99999999999996...|  0.0|       0.0|\n",
      "|      AssocissociaJj|        safe|[1.0,7.9761773657...|  0.0|       0.0|\n",
      "|                [[]]|        safe|[0.77761910317155...|  0.0|       0.0|\n",
      "|         1720|df=yes|        safe|[0.99999999751760...|  0.0|       0.0|\n",
      "|          Jr.|link=y|        safe|[0.99999999997264...|  0.0|       0.0|\n",
      "|        21twenty-fir|        safe|[0.99999999999963...|  0.0|       0.0|\n",
      "|<br>This is unlik...|        safe|[0.99999999999994...|  0.0|       0.0|\n",
      "|}}</ref>\n",
      "* ''West...|      unsafe|[5.72973309796331...|  1.0|       1.0|\n",
      "|\n",
      "|-\n",
      "|}\n",
      "\n",
      "====Sarco...|        safe|[0.99999999999999...|  0.0|       0.0|\n",
      "+--------------------+------------+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+------------+--------------------+-----+----------+\n",
      "|          difference|label_string|         probability|label|prediction|\n",
      "+--------------------+------------+--------------------+-----+----------+\n",
      "|                 Jr.|        safe|[0.99999999999999...|  0.0|       0.0|\n",
      "|      Jr. Jr.|link=y|        safe|[0.99999999999392...|  0.0|       0.0|\n",
      "|must s probably b...|        safe|[1.0,1.4783380142...|  0.0|       0.0|\n",
      "|[[enmark|IFPI D]]...|        safe|[0.06398903709249...|  0.0|       1.0|\n",
      "|                  \n",
      "\n",
      "|        safe|[0.90058597981852...|  0.0|       0.0|\n",
      "|                 n a|      unsafe|[0.99410599129165...|  1.0|       0.0|\n",
      "|>|ref1=<ref>https...|      unsafe|[0.99999999794906...|  1.0|       0.0|\n",
      "|\n",
      "* [[Kemal Reis]]...|      unsafe|[1.43755191306824...|  1.0|       1.0|\n",
      "|    MaySeptember1820|        safe|[0.68605345534325...|  0.0|       0.0|\n",
      "|                  -–|        safe|[0.99999999996669...|  0.0|       0.0|\n",
      "|       Augustinians||        safe|[1.0,3.9272209568...|  0.0|       0.0|\n",
      "|       s|Augustinian|        safe|[1.0,7.7778268627...|  0.0|       0.0|\n",
      "|s|AugustinianAugu...|        safe|[1.0,4.7608820554...|  0.0|       0.0|\n",
      "||Baxter|MitchellB...|        safe|[0.99724866347806...|  0.0|       0.0|\n",
      "|       s|Augustinian|        safe|[0.99999999999999...|  0.0|       0.0|\n",
      "|film)|''Marshal''...|        safe|[0.99999999999999...|  0.0|       0.0|\n",
      "|         sphighrcial|        safe|[0.99999997677936...|  0.0|       0.0|\n",
      "|upright=0.75|upri...|        safe|[3.17559316588197...|  0.0|       1.0|\n",
      "|                   t|        safe|[0.99999999997636...|  0.0|       0.0|\n",
      "|                [[]]|        safe|[0.93672698231927...|  0.0|       0.0|\n",
      "+--------------------+------------+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_train_w.select(\"difference\",\"label_string\",\"probability\",\"label\",\"prediction\").show()\n",
    "predict_test_w.select(\"difference\",\"label_string\",\"probability\",\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE LOGISTIC REGRESSION WITH WEIGHTS\n",
    "\n",
    "#outpath = 'models/without_comment/logistic_regression_with_weights'\n",
    "#outpath = 'models/with_comment/logistic_regression_with_weights'\n",
    "\n",
    "#lrModel_w.write().overwrite().save(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LOGISTIC REGRESSION WITH WEIGHTS\n",
    "\n",
    "#from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "#LogisticRegressionModel.load('models/without_comment/logistic_regression_with_weights')\n",
    "#LogisticRegressionModel.load('models/with_comment/logistic_regression_with_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy train set: 0.9948936170212765\n",
      "overall accuracy test set: 0.826530612244898\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE MODEL ACCURACY FOR TRAIN AND TEST SETS\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol = \"label\", metricName=\"accuracy\")\n",
    "\n",
    "print(\"overall accuracy train set: %s\" % (evaluator.evaluate(predict_train_w)))\n",
    "print(\"overall accuracy test set: %s\" % (evaluator.evaluate(predict_test_w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for label 0 (safe): 0.9959798994974874\n",
      "training accuracy for label 1 (unsafe): 0.9875776397515528\n",
      "training accuracy for label 2 (vandal): 1.0\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE MODEL ACCURACY FOR TRAIN SET BY LABEL\n",
    "\n",
    "zeros_w = predict_train_w.where(\"label == 0\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 0 (safe): %s\" % (evaluator.evaluate(zeros_w)))\n",
    "\n",
    "ones_w = predict_train_w.where(\"label == 1\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 1 (unsafe): %s\" % (evaluator.evaluate(ones_w)))\n",
    "\n",
    "twos_w = predict_train_w.where(\"label == 2\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 2 (vandal): %s\" % (evaluator.evaluate(twos_w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy for label 0 (safe): 0.9292682926829269\n",
      "testing accuracy for label 1 (unsafe): 0.3333333333333333\n",
      "testing accuracy for label 2 (vandal): 0.0\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE MODEL ACCURACY FOR TEST SET BY LABEL\n",
    "\n",
    "zeros_test_w = predict_test_w.where(\"label == 0\").select(\"label\", \"prediction\")\n",
    "print(\"testing accuracy for label 0 (safe): %s\" % (evaluator.evaluate(zeros_test_w)))\n",
    "\n",
    "ones_test_w = predict_test_w.where(\"label == 1\").select(\"label\", \"prediction\")\n",
    "print(\"testing accuracy for label 1 (unsafe): %s\" % (evaluator.evaluate(ones_test_w)))\n",
    "\n",
    "twos_test_w = predict_test_w.where(\"label == 2\").select(\"label\", \"prediction\")\n",
    "print(\"testing accuracy for label 2 (vandal): %s\" % (evaluator.evaluate(twos_test_w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-FOLD CROSS-VALIDATION\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# model to cross-validate\n",
    "lr_cv = LogisticRegression(maxIter=20)\n",
    "\n",
    "# create ParamGrid for cross-validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr_cv.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr_cv.elasticNetParam, [0.0, 0.5, 1.0]) # Elastic Net Parameter\n",
    "             .build())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol = \"label\")\n",
    "\n",
    "# create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr_cv, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "\n",
    "# fit the model\n",
    "cvModel = cv.fit(dataset_tr)\n",
    "\n",
    "# predict train and test datasets\n",
    "predict_train_cv = cvModel.transform(dataset_tr)\n",
    "predict_test_cv = cvModel.transform(dataset_test)\n",
    "\n",
    "# show predictions\n",
    "predict_train_cv.select(\"difference\", \"probability\", \"label\", \"prediction\").show()\n",
    "predict_test_cv.select(\"difference\", \"probability\", \"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE PARAMETER VALUES OF THE BEST MODEL\n",
    "\n",
    "best_model = cvModel.bestModel\n",
    "print ('Best Param (regParam): ', best_model._java_obj.getRegParam())\n",
    "print ('Best Param (elasticNetParam): ', best_model._java_obj.getElasticNetParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE CV MODEL WITHOUT WEIGHTS\n",
    "\n",
    "#outpath = 'models/without_comment/logistic_regression_cv'\n",
    "#outpath = 'models/with_comment/logistic_regression_cv'\n",
    "\n",
    "#cvModel.write().overwrite().save(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD CV MODEL WITHOUT WEIGHTS\n",
    "\n",
    "#CrossValidator.load('models/without_comment/logistic_regression_cv')\n",
    "#CrossValidator.load('models/with_comment/logistic_regression_cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE OVERALL CV MODEL ACCURACY FOR TRAIN AND TEST SETS\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol = \"label\", metricName=\"accuracy\")\n",
    "\n",
    "print(\"overall accuracy train set: %s\" % (evaluator.evaluate(predict_train_cv)))\n",
    "print(\"overall accuracy test set: %s\" % (evaluator.evaluate(predict_test_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE CV MODEL ACCURACY FOR TRAIN SET BY LABEL\n",
    "\n",
    "zeros_cv = predict_train_cv.where(\"label == 0\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 0 (safe): %s\" % (evaluator.evaluate(zeros_cv)))\n",
    "\n",
    "ones_cv = predict_train_cv.where(\"label == 1\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 1 (unsafe): %s\" % (evaluator.evaluate(ones_cv)))\n",
    "\n",
    "twos_cv = predict_train_cv.where(\"label == 2\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 2 (vandal): %s\" % (evaluator.evaluate(twos_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE CV MODEL ACCURACY FOR TEST SET BY LABEL\n",
    "\n",
    "zeros_test_cv = predict_test_cv.where(\"label == 0\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 0 (safe): %s\" % (evaluator.evaluate(zeros_test_cv)))\n",
    "\n",
    "ones_test_cv = predict_test_cv.where(\"label == 1\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 1 (unsafe): %s\" % (evaluator.evaluate(ones_test_cv)))\n",
    "\n",
    "twos_test_cv = predict_test_cv.where(\"label == 2\").select(\"label\", \"prediction\")\n",
    "print(\"training accuracy for label 2 (vandal): %s\" % (evaluator.evaluate(twos_test_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##\n",
    "## NOTE !!!!!!\n",
    "##\n",
    "## THE FOLLOWING PART IS FOR TRAINING THE BEST MODEL ON THE WHOLE DATASET\n",
    "##\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE BEST MODEL -- WEIGHTED LOGISTIC REGRESSION WITH COMBINED 'COMMENT' AND 'DIFFERENCE' COLUMNS AS FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of 0s is 0.8438438438438438\n",
      "The percentage of 1s is 0.13993993993993994\n",
      "The percentage of 2s is 0.016216216216216273\n",
      "The weight of class safe is 1.1850533807829182\n",
      "The weight of class unsafe is 7.145922746781116\n",
      "The weight of class vandal is 61.66666666666645\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION WITH WEIGHTS -- CALCULATING WEIGHTS\n",
    "\n",
    "dataset_tr_size = float(dataset_tr.select(\"label\").count())\n",
    "\n",
    "numZeros = dataset_tr.select(\"label\").where('label == 0').count()\n",
    "perZeros = (float(numZeros)/float(dataset_tr_size))\n",
    "\n",
    "numOnes = dataset_tr.select(\"label\").where('label == 1').count()\n",
    "perOnes = (float(numOnes)/float(dataset_tr_size))\n",
    "\n",
    "perTwos = 1-perOnes-perZeros\n",
    "\n",
    "print('The percentage of 0s is {}'.format(perZeros))\n",
    "print('The percentage of 1s is {}'.format(perOnes))\n",
    "print('The percentage of 2s is {}'.format(perTwos))\n",
    "\n",
    "weight0 = 1/(perZeros)\n",
    "weight1 = 1/(perOnes)\n",
    "weight2 = 1/(perTwos)\n",
    "\n",
    "print('The weight of class safe is {}'.format(weight0))\n",
    "print('The weight of class unsafe is {}'.format(weight1))\n",
    "print('The weight of class vandal is {}'.format(weight2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|label|      classWeights|\n",
      "+-----+------------------+\n",
      "|  2.0| 61.66666666666645|\n",
      "|  2.0| 61.66666666666645|\n",
      "|  2.0| 61.66666666666645|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  1.0| 7.145922746781116|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  0.0|1.1850533807829182|\n",
      "|  1.0| 7.145922746781116|\n",
      "+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION WITH WEIGHTS -- ADDING WEIGHT COLUMN\n",
    "\n",
    "dataset_tr = dataset_tr.withColumn(\"classWeights\", F.when(dataset_tr.label == 0, weight0).when(dataset_tr.label == 1, weight1).otherwise(weight2))\n",
    "dataset_tr.select(\"label\",\"classWeights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION WITH WEIGHTS -- TRAINING AND PREDICTING\n",
    "\n",
    "# train\n",
    "lr_w = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", weightCol=\"classWeights\", maxIter=20)\n",
    "lrModel_w = lr_w.fit(dataset_tr)\n",
    "\n",
    "# predict\n",
    "predict_train_w = lrModel_w.transform(dataset_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+------------+----------+-----------------+\n",
      "|             comment|          difference|         probability|label|label_string|prediction|prediction_string|\n",
      "+--------------------+--------------------+--------------------+-----+------------+----------+-----------------+\n",
      "|                    |aFollow me o tikt...|[9.49730303155441...|  2.0|      vandal|       2.0|           vandal|\n",
      "|      (→‎Early life)|       he is amazing|[6.55907802473438...|  2.0|      vandal|       2.0|           vandal|\n",
      "|         (→‎History)|. and it's so stu...|[3.60613953939795...|  2.0|      vandal|       2.0|           vandal|\n",
      "|→‎Preseason All-S...|                 Jr.|[1.0,2.0271336158...|  0.0|        safe|       0.0|             safe|\n",
      "|→‎Churches:Fixing...|       Augustinians||[1.0,1.9652482166...|  0.0|        safe|       0.0|             safe|\n",
      "|→‎Churches holdin...|                   s|[1.0,3.1346578602...|  0.0|        safe|       0.0|             safe|\n",
      "|            →‎Roster|      Jr. Jr.|link=y|[1.0,9.8856412003...|  0.0|        safe|       0.0|             safe|\n",
      "|             grammar|must s probably b...|[1.0,5.4009979434...|  0.0|        safe|       0.0|             safe|\n",
      "|                    |                  39|[0.01426668221497...|  1.0|      unsafe|       1.0|           unsafe|\n",
      "|- 5 categories us...|English-language ...|[0.99999999999999...|  0.0|        safe|       0.0|             safe|\n",
      "|→‎Bibliography:am...|| last = Coogan |...|[1.0,1.0556309890...|  0.0|        safe|       0.0|             safe|\n",
      "|Fixed citation an...|                   t|[1.0,1.4826815858...|  0.0|        safe|       0.0|             safe|\n",
      "|→‎Appearances in ...|            (2009)y'|[1.0,3.1080606542...|  0.0|        safe|       0.0|             safe|\n",
      "|  →‎Season 17 (2020)|0.27<ref>{{cite w...|[1.0,1.4007756087...|  0.0|        safe|       0.0|             safe|\n",
      "|                    |[[enmark|IFPI D]]...|[0.99999879382284...|  0.0|        safe|       0.0|             safe|\n",
      "|external link rem...|  Italian vocalis...|[1.0,5.3249432219...|  0.0|        safe|       0.0|             safe|\n",
      "|          →‎Examples|                  \n",
      "\n",
      "|[0.99999999999997...|  0.0|        safe|       0.0|             safe|\n",
      "|→‎top:replaced: A...|      AssocissociaJj|[1.0,2.1385593797...|  0.0|        safe|       0.0|             safe|\n",
      "|                    |                [[]]|[0.54739470418626...|  0.0|        safe|       0.0|             safe|\n",
      "|(Reverted 1 edit ...|                 n a|[4.59072220659777...|  1.0|      unsafe|       1.0|           unsafe|\n",
      "+--------------------+--------------------+--------------------+-----+------------+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add predicted labels as strings (since now predictions are done only in terms of 0, 1 and 2)\n",
    "predictions_string = predict_train_w.withColumn(\"prediction_string\", F.when(predict_train_w.prediction == 0, \"safe\").when(predict_train_w.prediction == 1, \"unsafe\").otherwise(\"vandal\"))\n",
    "predictions_string.select(\"comment\", \"difference\", \"probability\", \"label\", \"label_string\" ,\"prediction\", \"prediction_string\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE BEST MODEL\n",
    "\n",
    "outpath = 'models/best/logistic_regression_with_weights_and_comment'\n",
    "\n",
    "lrModel_w.write().overwrite().save(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 0.9921921921921922\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE MODEL ACCURACY\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol = \"label\", metricName=\"accuracy\")\n",
    "\n",
    "print(\"overall accuracy: %s\" % (evaluator.evaluate(predict_train_w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for label 0 (safe): 0.994306049822064\n",
      "accuracy for label 1 (unsafe): 0.9785407725321889\n",
      "accuracy for label 2 (vandal): 1.0\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE MODEL ACCURACY BY LABEL\n",
    "\n",
    "zeros_w = predict_train_w.where(\"label == 0\").select(\"label\", \"prediction\")\n",
    "print(\"accuracy for label 0 (safe): %s\" % (evaluator.evaluate(zeros_w)))\n",
    "\n",
    "ones_w = predict_train_w.where(\"label == 1\").select(\"label\", \"prediction\")\n",
    "print(\"accuracy for label 1 (unsafe): %s\" % (evaluator.evaluate(ones_w)))\n",
    "\n",
    "twos_w = predict_train_w.where(\"label == 2\").select(\"label\", \"prediction\")\n",
    "print(\"accuracy for label 2 (vandal): %s\" % (evaluator.evaluate(twos_w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
